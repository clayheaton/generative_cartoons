{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "import spacy.en\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('punchlines.txt', 'r') as myfile:\n",
    "    data=myfile.read().split('\\n')\n",
    "    for line in data:\n",
    "        line = line.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = English(parser=False, tagger=True, entity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punchline_structures = []\n",
    "for punchline in data:\n",
    "    tokens = nlp(punchline)\n",
    "    tags = []\n",
    "    for toke in tokens:\n",
    "        tags.append((toke,toke.tag_))\n",
    "    punchline_structures.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store all words by part of speech identified by the tagger.\n",
    "all_words = {}\n",
    "for punchline in punchline_structures:\n",
    "    for word in punchline:\n",
    "        if word[1] not in all_words.keys():\n",
    "            all_words[word[1]] = []\n",
    "        all_words[word[1]].append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['JJR', '.', ':', 'NN', 'VBP', 'EX', 'RP', 'JJS', 'JJ', 'PRP$', 'VB', \"''\", 'NNS', 'IN', 'WP', 'POS', 'HYPH', 'NNP', '``', 'WRB', 'UH', 'VBD', 'PDT', 'WP$', 'PRP', 'VBZ', 'VBG', 'RB', ',', 'CD', 'VBN', 'MD', 'RBR', 'DT', 'TO', 'WDT', 'CC'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "structures = []\n",
    "for punchline_structure in punchline_structures:\n",
    "    s = []\n",
    "    for word in punchline_structure:\n",
    "        s.append(word[1])\n",
    "    structures.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there porridge not You can point intensity despite him?\n",
      "Please, and who we Obviously are to believe is be fireworks ' chants?\n",
      "You forgot disappeared not big in grilling - artifacts that used to see rocks here support The scene for artifacts.\n",
      "You will somewhere feel it not of it claimed.\n",
      "Potato: That artifacts.\n",
      "Hatfield, questioning, me have if the footage. me might Damn I wherever They think to That earth, and how it have for on the beer, how you get since a pay trance, and how They think if for this arm century... And them will walk you how it keep with The course? Early you have Next taking.\n",
      "And for a sorry one Six smiles me would point starting our damage?\n",
      "Yes bring secretly a little portfolio of the more passionate work.\n",
      "Last when it started to scream regulated regular outtakes in your lines.\n",
      "It get prepared Meticulously low to counting - smiles Which thought to last outtakes there write the earth for things.\n",
      "Is It watching to be into sheep notice.\n",
      "The is a giant head for their right you were I used not go.\n",
      "And we Is always a dinner - I am you.\n",
      "I have forgetting The identify our ugly vehicles, there his things.\n",
      "Is you starting to take in fashion scream.\n",
      "But touching trance Is you low.\n",
      "Support it, them have starting to get here nice He used up good game.\n",
      "I has For interesting.\n",
      "Sure, but what are I call in anyone what is Maybe starting.\n",
      "Quite not, not me is back no curvature. not I does not a news place on been darling with red drink, the man.\n",
      "Get the potato and have a rye how you get?\n",
      "Sure, gigantic, gigantic problem.\n",
      "Help we, it are watching to see really giant we shaved out sippy grant.\n",
      "Me did to take I, Jeb? it thought going eyes.\n",
      "Raton, brother, we have to The news. it will look I how he identify since a grant, but when I check with since the someone, wherever I am of The Man home, and how You have with into the conviction Warning, and him may Keep I how you are before those sir. Brooklyn me are not forgetting.\n",
      "Yes, little, little base.\n",
      "Oh, And who are I like by co what cooks not starting.\n",
      "Commandments? locally transmuting Russia Mommy in Monday makes everyone.\n",
      "O.K. shaved, my friends forgetting?\n",
      "That little Mom message. a bad Kids against I am seeded now dating a kugel questioning with a gold have proved to watch pathetic, and, thinking Goldilocks, him can call using a \" Peter Peter Jeb \" in Early hundred !\n",
      "Often it have the miracle of It.\n",
      "Ok, McCoy, be along on of these head. but Do ever get the lettuce? we is these conviction into the game identity back just.\n",
      "You have When we do it unless the enough.\n",
      "Such legal grilling chap.\n",
      "Are I been my romanticized situation.\n",
      "We are little - Where I shaved big conviction, me happened you were nice.\n",
      "I get into a children ' plane. Dumbledore is Maybe sourced the right of condo. Boca Liz does?\n",
      "Get It follow beer that is back say bottomless really.\n",
      "I can not get You not in I did?\n",
      "Channel, raise, I think into the work. You will Do You how you get out All tuna, and how it think despite of the salad, Why you go that all someone kid, But wherever they play in in that food apartment, But you can eat I when I know For the everyone. Mommy You are first demanding.\n",
      "They will stop of my market in you cut a crime.\n",
      "You want regular when it are last, but be a sir of them not in some conviction die but watch up?\n",
      "Oh have not The first scene in the more full year.\n",
      "You brought out in his body sticks, and I am become If a base.\n",
      "Of our martini, Glad?\n",
      "Will the get not, rent.\n",
      "I love If the eyes ' hotel. Monday looks Again granted All plane for bedroom. Dumbledore Hatfield is.\n",
      "You will call with your arm to I am this font.\n",
      "Brooklyn said, your outtakes thinking?\n",
      "With I am Next become 100 months, take back get it the of the divine course text until sure faces or parents.\n"
     ]
    }
   ],
   "source": [
    "def random_punchline():\n",
    "    # Pick a random structure.\n",
    "    struct = random.choice(structures)\n",
    "    punchline = []\n",
    "    for pos in struct:\n",
    "        word = random.choice(all_words[pos])\n",
    "        punchline.append(word)\n",
    "    \n",
    "    try:\n",
    "        punchline[0] = str(punchline[0]).title()\n",
    "    except:\n",
    "        print(punchline)\n",
    "        print(\"PROBLEM ABOVE\")\n",
    "        return(\"PROBLEM\")\n",
    "        \n",
    "    pline = \" \".join([str(w) for w in punchline])\n",
    "    pline = pline.replace(\"i are\",\"i am\")\n",
    "    pline = pline.replace(\"I are\",\"I am\")\n",
    "    pline = pline.replace(\"I is\",\"I am\")\n",
    "    pline = pline.replace(\"i is\",\"I am\")\n",
    "    pline = pline.replace(\"you am\",\"you are\")\n",
    "    pline = pline.replace(\"You am\",\"You are\")\n",
    "    pline = pline.replace(\"you is\",\"you are\")\n",
    "    pline = pline.replace(\"You am\",\"You are\")\n",
    "    pline = pline.replace(\"are n't\",\"aren't\")\n",
    "    pline = pline.replace(\" ?\",\"?\")\n",
    "    pline = pline.replace(\" .\",\".\")\n",
    "    pline = pline.replace(\" ,\",\",\")\n",
    "    pline = pline.replace(\" :\",\":\")\n",
    "    pline = pline.replace(\" ;\",\";\")\n",
    "    pline = pline.replace(\" i \",\" I \")\n",
    "    pline = pline.replace(\" i,\",\" I,\")\n",
    "    pline = pline.replace(\" i.\",\" I.\")\n",
    "    pline = pline.replace(\" 's\",\"'s\")\n",
    "    return pline\n",
    "    \n",
    "for n in range(50):\n",
    "    print(random_punchline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"structures.json\",'w') as f:\n",
    "    json.dump(structures,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_all_words = {}\n",
    "for key in all_words.keys():\n",
    "    str_all_words[key] = []\n",
    "    for word in all_words[key]:\n",
    "        if key == \"NNP\":\n",
    "            str_all_words[key].append(str(word))\n",
    "        else:\n",
    "            str_all_words[key].append(str(word).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"vocabulary.json\",'w') as f:\n",
    "    json.dump(str_all_words,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['JJR', '.', ':', 'NN', 'VBP', 'EX', 'RP', 'JJS', 'JJ', 'PRP$', 'VB', \"''\", 'NNS', 'IN', 'WP', 'POS', 'HYPH', 'NNP', '``', 'WRB', 'UH', 'VBD', 'PDT', 'WP$', 'PRP', 'VBZ', 'VBG', 'RB', ',', 'CD', 'VBN', 'MD', 'RBR', 'DT', 'TO', 'WDT', 'CC'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
